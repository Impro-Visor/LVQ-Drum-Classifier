{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os, csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LVQData:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        LVQData Constructor:\n",
    "            LVQData is a list of input vectors paired with their correct instrument classification.\n",
    "            LVQNet will iterate over this structure until it converges.\n",
    "        \"\"\"\n",
    "        self.data          = [] # list of tuples \n",
    "        self.instrumentMap = {} # map integers with instruments (labels)\n",
    "        self.instrumentNum = 0  # current integer instrument (to neuron)\n",
    "    \n",
    "    def getVectorData(self, index):\n",
    "        \"\"\"\n",
    "        Get the STFT of the Frame (1025 bins) at the specified index\n",
    "            index must be an valid integer\n",
    "        \"\"\"\n",
    "        return self.data[index][0]\n",
    "    \n",
    "    def getVectorLabel(self, index):\n",
    "        \"\"\"\n",
    "        Get the label of the Frame at the specified index\n",
    "            - index must be an valid integer\n",
    "        \"\"\"\n",
    "        return self.data[index][1]\n",
    "    \n",
    "    def getVector(self, index):\n",
    "        \"\"\"\n",
    "        Get the STFT data and label of the Frame at the specified index\n",
    "            - index must be an valid integer\n",
    "        \"\"\"\n",
    "        return self.data[index][0], self.data[index][1]\n",
    "    \n",
    "    def lookupInstrument(self, index):\n",
    "        \"\"\"\n",
    "        Lookup the instument specified by the number of the neuron\n",
    "            - index must be a valid integer\n",
    "        \"\"\"\n",
    "        return self.instrumentMap[index]\n",
    "    \n",
    "    def loadCSV(self, filepath, label):\n",
    "        \"\"\"\n",
    "        Add a STFT datapoint and label to the LVQData list\n",
    "            - filepath must be valid string from current working directory (os.getcwd() to check)\n",
    "            - label must be a string describing the instrument of the csv datapoints for entire CSV\n",
    "        \"\"\"\n",
    "        with open(filepath, 'r') as f:\n",
    "            read = csv.reader(f, delimiter=',')\n",
    "            read.next()\n",
    "            \n",
    "            for row in read:\n",
    "                data_struct = (arrayParser(row[1]), label) # Tuple with STFT bin list and then the label\n",
    "                self.data.append(data_struct)\n",
    "        \n",
    "            self.instrumentMap[self.instrumentNum] = label\n",
    "            self.instrumentNum += 1\n",
    "            \n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LVQNeuron:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.weights = []\n",
    "    \n",
    "    def setWeights(self, weights):\n",
    "        \"\"\"\n",
    "        Import a vector of information (the first entry) for initializing next unique neuron\n",
    "            - weights is a string from the import of a CSV\n",
    "        \"\"\"\n",
    "        weights = weights.replace('[', '').replace(']', '').split(',')\n",
    "        \n",
    "        for weight in weights:\n",
    "            self.weights.append(float(weight))\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LVQNet:\n",
    "    def __init__(self, inCount, outCount):\n",
    "        self.inputs   = inCount\n",
    "        self.outputs  = outCount\n",
    "        self.alpha    = 0.1\n",
    "        self.csvCount = 0  # Limit the CSVs input to number of output neurons\n",
    "        self.neurons  = {} # Numbered index map (to outputs)\n",
    "              \n",
    "        for n in range(outCount):\n",
    "            curr_neuron = LVQNeuron(n)\n",
    "            self.neurons[n] = curr_neuron\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.neurons)\n",
    "    \n",
    "    def getWeights(self, neuronNo):\n",
    "        \"\"\"\n",
    "        Get the current weights of the neuron specified\n",
    "            - neuronNo must be a valid integer\n",
    "        \"\"\"\n",
    "        return self.neurons[neuronNo].weights\n",
    "    \n",
    "    def setWeights(self, neuronNo, newWeights):\n",
    "        \"\"\"\n",
    "        Change the neuron weights with new Weight vector \n",
    "        \"\"\"\n",
    "        prev = self.neurons[neuronNo]\n",
    "        \n",
    "        if len(prev) == len(newWeights):\n",
    "            prev.weights = newWeights\n",
    "        \n",
    "    # STEP 0\n",
    "    def enterCSV(self, filepath): \n",
    "        if self.csvCount >= self.outputs:\n",
    "            print \"Reached limit of neurons\"\n",
    "            return\n",
    "            \n",
    "        with open(filepath, 'r') as f:\n",
    "            read = csv.reader(f, delimiter=',')\n",
    "            row = read.next()\n",
    "            curr_neuron = self.neurons[self.csvCount]\n",
    "            curr_neuron.setWeights(row[1])\n",
    "            self.csvCount += 1\n",
    "            \n",
    "            print \"Successfully added neuron from CSV\", filepath\n",
    "            return\n",
    "\n",
    "    # STEP 3.1\n",
    "    def edist(self, inputs, weights):\n",
    "        euclideanDistance = 0\n",
    "        \n",
    "        if len(inputs) != len(weights):\n",
    "            print len(inputs), \"is different length than\", len(weights)\n",
    "            return\n",
    "        \n",
    "        for i in range(len(inputs)):\n",
    "            nth = inputs[i] - weights[i]\n",
    "            nth = nth ** 2\n",
    "            euclideanDistance += nth\n",
    "             \n",
    "        return euclideanDistance ** (0.5)\n",
    "    \n",
    "    # STEP 3.2 \n",
    "    def minDist(self, inputVector):\n",
    "        scores = [] # Euclidean Distances\n",
    "        \n",
    "        for neuron in self.neurons:\n",
    "            wunit = self.neurons[neuron].weights\n",
    "            scores.append(self.edist(inputVector, wunit))\n",
    "        \n",
    "        minNeuronIndex = scores.index(min(scores))\n",
    "        return minNeuronIndex\n",
    "    \n",
    "    # STEP 4.1\n",
    "    def calibrate(self, neuronNo, guessNo):\n",
    "        \n",
    "        neuron      = dataset.getVectorLabel(neuronNo) \n",
    "        inputVector = dataset.getVectorData(neuronNo)\n",
    "        guess       = dataset.lookupInstrument(guessNo) \n",
    "        weights     = self.getWeights(guessNo)          \n",
    "        \n",
    "        addfunc = lambda oldWeight, vec: oldWeight + self.alpha * (vec - oldWeight)\n",
    "        subfunc = lambda oldWeight, vec: oldWeight - self.alpha * (vec - oldWeight)\n",
    "\n",
    "        if neuron == guess: \n",
    "            newWeights = map(addfunc, weights, inputVector) # assign weights as new weights\n",
    "            self.setWeights(guessNo, newWeights)\n",
    "        else:\n",
    "            newWeights = map(subfunc, weights, inputVector) # assign weights as new weights\n",
    "            self.setWeights(guessNo, newWeights)\n",
    "\n",
    "    # STEP 5\n",
    "    def reduceAlpha(self, value):\n",
    "        self.alpha -= value\n",
    "        return self.alpha\n",
    "    \n",
    "    # Altogether algorithm (TODO use Mean Squared error)\n",
    "    def run(self, ds):\n",
    "        # Data is datastructure (LVQData object that has been initialized with all CSVs)\n",
    "        if (len(ds.data) == 0):\n",
    "            print \"Need to initialize data in order to run the neural net\"\n",
    "        \n",
    "        else:\n",
    "            print \"Running the algorithm with \"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def arrayParser(arr):\n",
    "    # CSV usage: cast string list to python list\n",
    "    smooth_stage_1 = arr.replace('[', '').replace(']', '').split(',')\n",
    "    smooth_stage_2 = map(lambda unit: float(unit), smooth_stage_1)\n",
    "    return smooth_stage_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added neuron from CSV ./data/snareFrames.csv\n",
      "Successfully added neuron from CSV ./data/kickDrumFrames.csv\n"
     ]
    }
   ],
   "source": [
    "### Driver: Outline of the API / Algorithm in use    \n",
    "if __name__ == '__main__':\n",
    "    # Create Network with in and out neuron parameters\n",
    "    koho = LVQNet(1025, 2)\n",
    "    \n",
    "    # Enter data (1-1 CSV to Output Neurons) Initializes the neurons with first onset\n",
    "    koho.enterCSV('./data/snareFrames.csv')\n",
    "    koho.enterCSV('./data/kickDrumFrames.csv')\n",
    "    \n",
    "    # Instantiate LVQ Training Data Structure and load rest of CSVs with labels\n",
    "    dataset = LVQData()\n",
    "    dataset.loadCSV('./data/snareFrames.csv', 'snare')\n",
    "    dataset.loadCSV('./data/kickDrumFrames.csv', 'kick-drum')\n",
    "    \n",
    "    # (TODO) Put the koho minDists in loop / logic\n",
    "    guess = koho.minDist(dataset.getVectorData(2))  # using a specific sample frame (snare)\n",
    "    guess2 = koho.minDist(dataset.getVectorData(8)) # using another sample frame (kick)\n",
    "    \n",
    "    # (TODO) Test calibrations\n",
    "    newWeights  = koho.calibrate(2, guess)\n",
    "    newWeights2 = koho.calibrate(8, guess2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
