{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os, csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LVQData:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        LVQData Constructor:\n",
    "            LVQData is a list of input vectors paired with their correct instrument classification.\n",
    "            LVQNet will iterate over this structure until it converges.\n",
    "        \"\"\"\n",
    "        self.data          = [] # list of tuples \n",
    "        self.instrumentMap = {} # map integers with instruments (labels)\n",
    "        self.instrumentNum = 0  # current integer instrument (to neuron)\n",
    "    \n",
    "    def getVectorData(self, index):\n",
    "        \"\"\"\n",
    "        Get the STFT of the Frame (1025 bins) at the specified index\n",
    "            index must be an valid integer\n",
    "        \"\"\"\n",
    "        return self.data[index][0]\n",
    "    \n",
    "    def getVectorLabel(self, index):\n",
    "        \"\"\"\n",
    "        Get the label of the Frame at the specified index\n",
    "            - index must be an valid integer\n",
    "        \"\"\"\n",
    "        return self.data[index][1]\n",
    "    \n",
    "    def getVector(self, index):\n",
    "        \"\"\"\n",
    "        Get the STFT data and label of the Frame at the specified index\n",
    "            - index must be an valid integer\n",
    "        \"\"\"\n",
    "        return self.data[index][0], self.data[index][1]\n",
    "    \n",
    "    def lookupInstrument(self, index):\n",
    "        \"\"\"\n",
    "        Lookup the instument specified by the number of the neuron\n",
    "            - index must be a valid integer\n",
    "        \"\"\"\n",
    "        return self.instrumentMap[index]\n",
    "    \n",
    "    def loadCSV(self, filepath, label):\n",
    "        \"\"\"\n",
    "        Add a STFT datapoint and label to the LVQData list\n",
    "            - filepath must be valid string from current working directory (os.getcwd() to check)\n",
    "            - label must be a string describing the instrument of the csv datapoints for entire CSV\n",
    "        \"\"\"\n",
    "        with open(filepath, 'r') as f:\n",
    "            read = csv.reader(f, delimiter=',')\n",
    "            read.next()\n",
    "            \n",
    "            for row in read:\n",
    "                data_struct = (arrayParser(row[1]), label) # Tuple with STFT bin list and then the label\n",
    "                self.data.append(data_struct)\n",
    "        \n",
    "            self.instrumentMap[self.instrumentNum] = label\n",
    "            self.instrumentNum += 1\n",
    "            \n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LVQNeuron:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.weights = []\n",
    "    \n",
    "    def setWeights(self, weights):\n",
    "        \"\"\"\n",
    "        Import a vector of information (the first entry) for initializing next unique neuron\n",
    "            - weights is a string from the import of a CSV\n",
    "        \"\"\"\n",
    "        weights = weights.replace('[', '').replace(']', '').split(',')\n",
    "        \n",
    "        for weight in weights:\n",
    "            self.weights.append(float(weight))\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LVQNet:\n",
    "    def __init__(self, inCount, outCount):\n",
    "        self.inputs   = inCount\n",
    "        self.outputs  = outCount\n",
    "        self.alpha    = 0.1\n",
    "        self.csvCount = 0  # Limit the CSVs input to number of output neurons\n",
    "        self.iter     = 0  # Number of times the vectors have been used in training\n",
    "        self.neurons  = {} # Numbered index map (to outputs)\n",
    "\n",
    "              \n",
    "        for n in range(outCount):\n",
    "            curr_neuron = LVQNeuron(n)\n",
    "            self.neurons[n] = curr_neuron\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.neurons)\n",
    "    \n",
    "    def getWeights(self, neuronNo):\n",
    "        \"\"\"\n",
    "        Get the current weights of the neuron specified\n",
    "            - neuronNo must be a valid integer\n",
    "        \"\"\"\n",
    "        return self.neurons[neuronNo].weights\n",
    "    \n",
    "    def setWeights(self, neuronNo, newWeights):\n",
    "        \"\"\"\n",
    "        Change the neuron weights with new Weight vector\n",
    "            - neuronNo must be a valid integer\n",
    "            - newWeights must be a list of numbers the same length as the previous weights\n",
    "        \"\"\"\n",
    "        prev = self.neurons[neuronNo]\n",
    "        \n",
    "        if len(prev) == len(newWeights):\n",
    "            prev.weights = newWeights\n",
    "        \n",
    "    # STEP 0\n",
    "    def enterCSV(self, filepath): \n",
    "        \"\"\"\n",
    "        Initialize neurons with first row of data in CSV (each CSV should represent a neuron)\n",
    "            - filepath must be valid string from current working directory (os.getcwd() to check)\n",
    "        \"\"\"\n",
    "        if self.csvCount >= self.outputs:\n",
    "            print \"Reached limit of neurons\"\n",
    "            return\n",
    "            \n",
    "        with open(filepath, 'r') as f:\n",
    "            read = csv.reader(f, delimiter=',')\n",
    "            row = read.next()\n",
    "            curr_neuron = self.neurons[self.csvCount]\n",
    "            curr_neuron.setWeights(row[1])\n",
    "            self.csvCount += 1\n",
    "            \n",
    "            print \"Successfully added neuron from CSV\", filepath\n",
    "            return\n",
    "\n",
    "    # STEP 3.1\n",
    "    def edist(self, inputs, weights):\n",
    "        \"\"\"\n",
    "        Helper function to get the Euclidean distance between input vector and neuron weights\n",
    "            - inputs must be list of numbers with same number of items as weights\n",
    "            - weights must be a valid list of neuron weights \n",
    "        \"\"\"\n",
    "        euclideanDistance = 0\n",
    "        \n",
    "        if len(inputs) != len(weights):\n",
    "            print len(inputs), \"is different length than\", len(weights)\n",
    "            return\n",
    "        \n",
    "        for i in range(len(inputs)):\n",
    "            nth = inputs[i] - weights[i]\n",
    "            nth = nth ** 2\n",
    "            euclideanDistance += nth\n",
    "             \n",
    "        return euclideanDistance ** (0.5)\n",
    "    \n",
    "    # STEP 3.2 \n",
    "    def minDist(self, inputVector):\n",
    "        \"\"\"\n",
    "        Given a input vector calculate the closest (guess) neuron to classify as\n",
    "            - inputVector must be list of numbers with same number of items as the neuron weights\n",
    "        \"\"\"\n",
    "        scores = [] # Euclidean Distances\n",
    "        \n",
    "        for neuron in self.neurons:\n",
    "            wunit = self.neurons[neuron].weights\n",
    "            scores.append(self.edist(inputVector, wunit))\n",
    "        \n",
    "        minNeuronIndex = scores.index(min(scores))\n",
    "        return minNeuronIndex\n",
    "    \n",
    "    # STEP 4.1\n",
    "    def calibrate(self, neuronNo, guessNo):\n",
    "        \"\"\"\n",
    "        Given a neuron number and a guess neuron number, first check to see if the guess was correct \n",
    "        or not and then calibrate the neurons accordingly (increase if correct, decrease if incorrect)\n",
    "            - neuronNo must be a valid integer (between 0 and total number of neurons - 1)\n",
    "            - guessNo  must be a valid integer (between 0 and total number of neurons - 1)\n",
    "        \"\"\"\n",
    "        neuron      = dataset.getVectorLabel(neuronNo) \n",
    "        inputVector = dataset.getVectorData(neuronNo)\n",
    "        guess       = dataset.lookupInstrument(guessNo) \n",
    "        weights     = self.getWeights(guessNo)     \n",
    "        \n",
    "        addfunc = lambda oldWeight, vec: oldWeight + self.alpha * (vec - oldWeight)\n",
    "        subfunc = lambda oldWeight, vec: oldWeight - self.alpha * (vec - oldWeight)\n",
    "\n",
    "        if neuron == guess: \n",
    "            newWeights = map(addfunc, weights, inputVector) # assign weights as new weights\n",
    "            self.setWeights(guessNo, newWeights)\n",
    "            return newWeights\n",
    "        else:\n",
    "            newWeights = map(subfunc, weights, inputVector) # assign weights as new weights\n",
    "            self.setWeights(guessNo, newWeights)\n",
    "            return newWeights\n",
    "\n",
    "    # STEP 5\n",
    "    def reduceAlpha(self, value):\n",
    "        \"\"\"\n",
    "        Helper function to reduce alpha value\n",
    "            - value must be a number greater than 0 but less than / equal to alpha\n",
    "        \"\"\"\n",
    "        self.alpha -= value\n",
    "        return self.alpha\n",
    "    \n",
    "    def iteration(self, dataset): # Helper function for iterating through during run function\n",
    "        \"\"\"\n",
    "        Given a dataset, iteration goes through each vector and calibrates the neurons \n",
    "        using the calibrate function\n",
    "            - dataset must be a list of tuples including vectors with correct dimensions \n",
    "            and classification labels\n",
    "        \"\"\"\n",
    "        length = range(len(dataset.data))\n",
    "        for v in length:\n",
    "            # v is the dataset.data index while vector is the input vector\n",
    "            vector = dataset.data[v]\n",
    "            guess = self.minDist(vector[0])\n",
    "            newWeights = self.calibrate(v, guess)\n",
    "            \n",
    "    @staticmethod        \n",
    "    def meanSquaredError(oldList, newList):\n",
    "        \"\"\"\n",
    "        MeanSquaredError will return a averages from the difference between the old neuron weight\n",
    "        and new neuron weight squared.\n",
    "            - oldList must be a list of weights that has the same dimensions as newList\n",
    "            - newList must be a list of weights that has the same dimensions as the neuron weights\n",
    "        \"\"\"\n",
    "        diffSquared = lambda a, b : (a - b) ** 2\n",
    "        average     = lambda arr  :  float(sum(arr) / len(arr))\n",
    "        \n",
    "        diffs = map(diffSquared, oldList, newList)\n",
    "        return average(diffs)\n",
    "        \n",
    "    def run(self, ds):\n",
    "        \"\"\"\n",
    "        Run the algorithm given a LVQData object that has been initialized with all the CSVs\n",
    "            - ds must have same number of CSVs initialized as neurons training \n",
    "            (or classifications)\n",
    "        \"\"\"\n",
    "        if (len(ds.data) == 0):\n",
    "            print \"Need to initialize data in order to run the neural net.\"\n",
    "            return\n",
    "        else:\n",
    "            self.iter += 1\n",
    "            print \"Running the algorithm with %d vectors. Iteration #%d.\" % (len(ds.data), self.iter)\n",
    "        \n",
    "        oldW = [] # Debug Before \n",
    "        for neuron in range(len(self.neurons)):\n",
    "            w = self.getWeights(neuron)\n",
    "            oldW.append(w)\n",
    "            \n",
    "        self.iteration(ds)\n",
    "        \n",
    "\n",
    "        newW = [] # Debug After\n",
    "        for neuron in range(len(self.neurons)):\n",
    "            w = self.getWeights(neuron)\n",
    "            newW.append(w)\n",
    "        \n",
    "        means   = []\n",
    "        average = lambda arr  :  float(sum(arr) / len(arr))\n",
    "        for n in range(len(oldW)):\n",
    "            means.append(LVQNet.meanSquaredError(oldW[n], newW[n]))\n",
    "            \n",
    "        return average(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def arrayParser(arr):\n",
    "    \"\"\"\n",
    "    ArrayParser takes an array created from reading a CSV into memory and turns the lists-strings\n",
    "    and casts them to a valid python list\n",
    "        - arr must be a string that has the same format as a python list\n",
    "    \"\"\"\n",
    "    # CSV usage: cast string list to python list\n",
    "    smooth_stage_1 = arr.replace('[', '').replace(']', '').split(',')\n",
    "    smooth_stage_2 = map(lambda unit: float(unit), smooth_stage_1)\n",
    "    return smooth_stage_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added neuron from CSV ./data/snareFrames.csv\n",
      "Successfully added neuron from CSV ./data/kickDrumFrames.csv\n",
      "Running the algorithm with 14 vectors. Iteration #1.\n",
      "39.088435798\n",
      "Running the algorithm with 14 vectors. Iteration #2.\n",
      "8.94218033139\n",
      "Running the algorithm with 14 vectors. Iteration #3.\n",
      "2.04568403536\n",
      "Running the algorithm with 14 vectors. Iteration #4.\n",
      "0.467986891054\n",
      "Running the algorithm with 14 vectors. Iteration #5.\n",
      "0.107060389783\n",
      "Running the algorithm with 14 vectors. Iteration #6.\n",
      "0.0244919831721\n",
      "Running the algorithm with 14 vectors. Iteration #7.\n",
      "0.00560298015838\n",
      "Running the algorithm with 14 vectors. Iteration #8.\n",
      "0.00128178214213\n",
      "Running the algorithm with 14 vectors. Iteration #9.\n",
      "0.000293230640379\n",
      "Running the algorithm with 14 vectors. Iteration #10.\n",
      "6.70817650138e-05\n",
      "Running the algorithm with 14 vectors. Iteration #11.\n",
      "1.53461561573e-05\n",
      "Running the algorithm with 14 vectors. Iteration #12.\n",
      "3.51070829392e-06\n",
      "Running the algorithm with 14 vectors. Iteration #13.\n",
      "8.03137450099e-07\n",
      "Running the algorithm with 14 vectors. Iteration #14.\n",
      "1.83732087586e-07\n",
      "Running the algorithm with 14 vectors. Iteration #15.\n",
      "4.20320083508e-08\n",
      "Running the algorithm with 14 vectors. Iteration #16.\n",
      "9.6155753149e-09\n",
      "Running the algorithm with 14 vectors. Iteration #17.\n",
      "2.19973520839e-09\n",
      "Running the algorithm with 14 vectors. Iteration #18.\n",
      "5.0322885808e-10\n",
      "Running the algorithm with 14 vectors. Iteration #19.\n",
      "1.15122621454e-10\n",
      "Running the algorithm with 14 vectors. Iteration #20.\n",
      "2.63363631776e-11\n"
     ]
    }
   ],
   "source": [
    "### Driver: Outline of the API / Algorithm in use    \n",
    "if __name__ == '__main__':\n",
    "    # Create Network with in and out neuron parameters\n",
    "    koho = LVQNet(1025, 2)\n",
    "    \n",
    "    # Enter data (1-1 CSV to Output Neurons) \n",
    "    # Initializes the neurons with first onset from each unique CSV\n",
    "    koho.enterCSV('./data/snareFrames.csv')\n",
    "    koho.enterCSV('./data/kickDrumFrames.csv')\n",
    "    \n",
    "    # Instantiate LVQ Training Data Structure and load rest of CSVs with labels\n",
    "    dataset = LVQData()\n",
    "    dataset.loadCSV('./data/snareFrames.csv',    'snare')\n",
    "    dataset.loadCSV('./data/kickDrumFrames.csv', 'kick-drum')\n",
    "\n",
    "    sigma = 1\n",
    "    while (sigma > 0.0000000001):\n",
    "        sigma = koho.run(dataset)\n",
    "        print sigma"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
