{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def arrayParser(arr):\n",
    "    # CSV cast string list to python list\n",
    "    smooth_stage_1 = arr.replace('[', '').replace(']', '').split(',')\n",
    "    smooth_stage_2 = map(lambda unit: float(unit), smooth_stage_1)\n",
    "    return smooth_stage_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LVQNeuron:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.weights = []\n",
    "    \n",
    "    def setWeights(self, weights):\n",
    "        weights = weights.replace('[', '').replace(']', '').split(',')\n",
    "        \n",
    "        for weight in weights:\n",
    "            self.weights.append(float(weight))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LVQNet:\n",
    "    def __init__(self, inCount, outCount):\n",
    "        self.inputs   = inCount\n",
    "        self.outputs  = outCount\n",
    "        self.alpha    = 0.1\n",
    "        self.csvCount = 0  # Limit the csvs input to number of output neurons\n",
    "        self.neurons  = {} # Numbered index map (to outputs)\n",
    "              \n",
    "        for n in range(outCount):\n",
    "            curr_neuron = LVQNeuron(n)\n",
    "            self.neurons[n] = curr_neuron\n",
    "        \n",
    "    def enterCSV(self, filepath):\n",
    "        if self.csvCount >= self.outputs:\n",
    "            print \"Reached limit of neurons\"\n",
    "            return\n",
    "            \n",
    "        with open(filepath, 'r') as f:\n",
    "            read = csv.reader(f, delimiter=',')\n",
    "            row = read.next()\n",
    "            curr_neuron = self.neurons[self.csvCount]\n",
    "            curr_neuron.setWeights(row[1])\n",
    "            self.csvCount += 1\n",
    "            \n",
    "            print \"Successfully added neuron from CSV\", filepath\n",
    "            return\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.neurons)\n",
    "    \n",
    "    def edist(self, inputs, weights):\n",
    "        # Euclidean Distance helper function \n",
    "        euclideanDistance = 0\n",
    "        \n",
    "        if len(inputs) != len(weights):\n",
    "            return\n",
    "        \n",
    "        for i in inputs:\n",
    "            nth = inputs[i] - weights[i]\n",
    "            nth = nth ** 2\n",
    "            euclideanDistance += nth\n",
    "            \n",
    "        return euclideanDistance ** (0.5)\n",
    "    \n",
    "    def minDist(self, inputVector):\n",
    "        for neuron in self.neurons:\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LVQData:\n",
    "    def __init__(self):\n",
    "        self.data = [] # list of tuples \n",
    "    \n",
    "    def loadCSV(self, filepath, label):\n",
    "        # Will skip first line of each CSV since LVQ initializes using the first lines\n",
    "        with open(filepath, 'r') as f:\n",
    "            read = csv.reader(f, delimiter=',')\n",
    "            read.next()\n",
    "            \n",
    "            for row in read:\n",
    "                # Tuple with STFT bins and then the label\n",
    "                data_struct = (arrayParser(row[1]), label)\n",
    "                self.data.append(data_struct)\n",
    "                \n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added neuron from CSV ./data/snareFrames.csv\n",
      "Successfully added neuron from CSV ./data/kickDrumFrames.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Create Network with in and out neuron parameters\n",
    "    koho = LVQNet(1025, 3)\n",
    "    \n",
    "    # Enter data (1-1 CSV to Output Neurons) Initializes the neurons with first onset\n",
    "    koho.enterCSV('./data/snareFrames.csv')\n",
    "    koho.enterCSV('./data/kickDrumFrames.csv')\n",
    "    \n",
    "    # Instantiate LVQ Training Data Structure and load rest of CSVs with labels\n",
    "    dataset = LVQData()\n",
    "    dataset.loadCSV('./data/snareFrames.csv', 'snare')\n",
    "    dataset.loadCSV('./data/kickDrumFrames.csv', 'kickdrum')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
